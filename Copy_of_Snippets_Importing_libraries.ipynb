{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import requests\n",
        "import time\n",
        "import nltk\n",
        "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.tokenize import word_tokenize, MWETokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
        "\n",
        "\n",
        "class ScraperAlgorithm:\n",
        "  class Scraper(ABC):\n",
        "    def scrape(self, url):\n",
        "      pass\n",
        "\n",
        "class WebsiteClient:\n",
        "  def __init__(self, scraper):\n",
        "    self.scraper =  scraper;\n",
        "\n",
        "  def main_article(self, url):\n",
        "    return self.scraper.scrape(url);\n",
        "\n",
        "class NTWebsite(ScraperAlgorithm):\n",
        "  # StoryBodyCompanionColumn\n",
        "  article_content = [];\n",
        "  def scrape(self, url):\n",
        "    res = requests.get(url, headers=headers);\n",
        "    soup = BeautifulSoup(res.content, 'html.parser');\n",
        "    for i in soup.findAll('div', attrs={\"class\":\"StoryBodyCompanionColumn\"}):\n",
        "      content = i.find('p').get_text();\n",
        "      self.article_content.append(content);\n",
        "    \n",
        "    return self.article_content;\n",
        "    \n",
        "\n",
        "class GuardianWebsite(ScraperAlgorithm):\n",
        "  # dcr-n6w1lc\n",
        "  article_content = [];\n",
        "  def scrape(self, url):\n",
        "    res = requests.get(url, headers=headers);\n",
        "    soup = BeautifulSoup(res.content, 'html.parser');\n",
        "    for i in soup.findAll('p', attrs={\"class\":\"dcr-n6w1lc\"}):\n",
        "      content = i.get_text();\n",
        "      self.article_content.append(content);\n",
        "    \n",
        "    return self.article_content;\n",
        "  \n",
        "# allowed_website=[\"theguardian\", \"The New York Times\"]\n",
        "# https://www.nytimes.com/2023/05/19/sports/superstar-billy-graham-dead.html\n",
        "NT = NTWebsite()\n",
        "\n",
        "client = WebsiteClient(NT);\n",
        "contents = client.main_article(\"https://www.nytimes.com/2023/05/19/business/amazon-union-choke-points.html\");\n",
        "\n",
        "text = \"\".join(contents).lower();\n",
        "\n",
        "\n",
        "#######################################################################################################\n",
        "stopwords = set(stopwords.words(\"english\"));\n",
        "\n",
        "def clean_text(text):\n",
        "  articles_tokenize = word_tokenize(text);\n",
        "  punctuations = r\".,\\\"-\\\\/#!?$%\\^&\\*;:{}=\\-_'~()\";\n",
        "  articles_tokenize = [token for token in articles_tokenize if len(token) > 4 and \n",
        "                      token not in stopwords and token not in punctuations];\n",
        "\n",
        "\n",
        "  lemma = WordNetLemmatizer()\n",
        "  articles_tokenize = [lemma.lemmatize(token) for token in articles_tokenize]\n",
        "\n",
        "  return \" \".join(articles_tokenize);\n",
        "\n",
        "# search_for_bigram = BigramCollocationFinder.from_documents(articles_tokenize);\n",
        "# search_for_bigram.apply_freq_filter(min_freq=3)\n",
        "# bigram = list(search_for_bigram.ngram_fd.items());\n",
        "\n",
        "# search_for_trigram = TrigramCollocationFinder.from_documents(articles_tokenize);\n",
        "# search_for_trigram.apply_freq_filter(min_freq=3);\n",
        "# trigram = list(search_for_trigram.ngram_fd.items());\n",
        "\n",
        "\n",
        "# bigrams = [bigram for bigram, freq in search_for_bigram.ngram_fd.items()]\n",
        "# trigrams = [trigram for trigram, freq in search_for_trigram.ngram_fd.items()]\n",
        "\n",
        "\n",
        "# mwe_tokenizer = MWETokenizer(bigrams + trigrams, separator='_')\n",
        "# articles_tokenize = [mwe_tokenizer.tokenize(article) for article in articles_tokenize]\n",
        "\n",
        "\n",
        "model = clean_text(text);\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "eiZdajAJ8q9E",
        "outputId": "4990ac4a-2ba6-4163-ab11-33a62a074a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "familiar corporate dominance amazon delivery employee loose costly concession amazon worker threaten choke point within delivery network appear concession multiple times.amazon recent growth helped create choke point worker sought exploit first decade company stayed delivery business simply handed razor blade like fedex postal service.amazon began transporting package holiday season surge order backed carrier later pandemic amazon significantly increased transportation footprint handle order seeking drive delivery time hence vans.and amazon chief executive jassy seek drive shipping time disruptive potential organizing growing.on evening local leader fledgling united automobile worker flashed light outside union office across massive general motor plant flint mich. summoning plant steward plant condition deteriorated least grueling speed-up required worker thousand motion union decided strike recognition steward returned plant employee stopped working refused leave.amazon moved different direction automaker century making vulnerable business ballooned.according mwpvl international consulting small portion amazon fulfillment center extremely volume good million item period including staten island warehouse worker voted amazon labor union spring.some worker advantage organizer center staten island whether unionize focused building enough support force shutdown building sort package delivery station area.delivery station center package loaded similarly vulnerable company declined increase worker chicago area.but shortly worker delivery station walked december company increased worker building pretty clear walkout raise said.while mobilizing hundred worker fulfillment center daunting walkout several dozen delivery station worker could delay thousand package supposed morning.there arguably bigger target organizer amazon company million package across large distance bernardino handful increasingly backbone company transit system.this appears given worker leverage addition asking return winter company announced raising hourly night shift nearly august significant addition nationwide increase roughly 1,500 employee added name petition seeking higher pay.the number employee kentucky 2,000 number flight grown substantially since facility opened almost year chaddick institute metropolitan development depaul university estimate number amazon flight typical doubled early early group organizer submitted petition name roughly worker asking company restore bonus permanent member group later announced seeking unionize.the effort funded member left-wing group socialist alternative appears attracted attention amazon recently amazon labor union president christian small appeared kentucky march offer union support company began regularly holding meeting worker dwelled drawback unionizing according recording meetings.workers union election kentucky order extract concession company.the company clearly understands stake worker manager frequently employee driver become tug-trained operate event driver shortage amazon common cross-train worker manager provided support coaching employee backed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/BBC News Train.csv\");\n",
        "df.drop(\"ArticleId\", axis=1, inplace=True)\n",
        "\n",
        "df[\"Text\"] = df['Text'].apply(clean_text);\n",
        "\n",
        "vectorizer = CountVectorizer();\n",
        "X = vectorizer.fit_transform(df['Text']);\n",
        "y = df['Category'];\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred = nb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", (accuracy*100),'%')\n",
        "print(\"Precision:\", (precision*100),'%')\n",
        "print(\"Recall:\", (recall*100),'%')\n",
        "print('F1-score:', (f1*100),'%')\n",
        "\n",
        "article_vectorized = vectorizer.transform([model])\n",
        "category = nb_model.predict(article_vectorized)[0]\n",
        "print(\"Predicted category:\", category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL1FtZ9mX91y",
        "outputId": "7db0e0a2-af84-49b2-9e65-e3cebc44a317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.97986577181209 %\n",
            "Precision: 97.00798886516169 %\n",
            "Recall: 96.97986577181209 %\n",
            "F1-score: 96.98081492191 %\n",
            "Predicted category: business\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dQJg8WkafAyx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}